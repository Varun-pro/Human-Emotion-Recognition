{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T15:30:26.603089Z","iopub.execute_input":"2022-04-13T15:30:26.603624Z","iopub.status.idle":"2022-04-13T15:30:26.632680Z","shell.execute_reply.started":"2022-04-13T15:30:26.603531Z","shell.execute_reply":"2022-04-13T15:30:26.632068Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,BatchNormalization,Dense,Dropout,Flatten,GlobalAveragePooling2D,Activation,MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:29.065997Z","iopub.execute_input":"2022-04-13T15:30:29.066293Z","iopub.status.idle":"2022-04-13T15:30:34.741673Z","shell.execute_reply.started":"2022-04-13T15:30:29.066264Z","shell.execute_reply":"2022-04-13T15:30:34.740862Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_path='/kaggle/input/fer2013/train'\ntest_path='/kaggle/input/fer2013/test'","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:34.743276Z","iopub.execute_input":"2022-04-13T15:30:34.743510Z","iopub.status.idle":"2022-04-13T15:30:34.747442Z","shell.execute_reply.started":"2022-04-13T15:30:34.743478Z","shell.execute_reply":"2022-04-13T15:30:34.746858Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"os.listdir(train_path+'/angry/')[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:34.748561Z","iopub.execute_input":"2022-04-13T15:30:34.748917Z","iopub.status.idle":"2022-04-13T15:30:34.901233Z","shell.execute_reply.started":"2022-04-13T15:30:34.748882Z","shell.execute_reply":"2022-04-13T15:30:34.900628Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image=cv2.imread(train_path+'/angry/Training_51319902.jpg')\nimport matplotlib.pyplot as plt\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:34.902995Z","iopub.execute_input":"2022-04-13T15:30:34.903264Z","iopub.status.idle":"2022-04-13T15:30:35.129467Z","shell.execute_reply.started":"2022-04-13T15:30:34.903231Z","shell.execute_reply":"2022-04-13T15:30:35.128755Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"img_gen=ImageDataGenerator(rotation_range=30, fill_mode='nearest',width_shift_range=0.2, height_shift_range=0.2,\n                                 horizontal_flip=True, vertical_flip=True,\n                                 brightness_range=[0.4,1.5],\n                                 zoom_range=0.3,\n                                 rescale=1/255.0)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:35.534039Z","iopub.execute_input":"2022-04-13T15:30:35.534433Z","iopub.status.idle":"2022-04-13T15:30:35.544237Z","shell.execute_reply.started":"2022-04-13T15:30:35.534404Z","shell.execute_reply":"2022-04-13T15:30:35.542957Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data=img_gen.flow_from_directory(train_path,color_mode = 'grayscale',class_mode='categorical',target_size=(48,48),shuffle=True,batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:40.869435Z","iopub.execute_input":"2022-04-13T15:30:40.869856Z","iopub.status.idle":"2022-04-13T15:30:50.211740Z","shell.execute_reply.started":"2022-04-13T15:30:40.869824Z","shell.execute_reply":"2022-04-13T15:30:50.209572Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_data=img_gen.flow_from_directory(test_path,color_mode = 'grayscale',class_mode='categorical',target_size=(48,48),shuffle=True,batch_size=512)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:50.213497Z","iopub.execute_input":"2022-04-13T15:30:50.213761Z","iopub.status.idle":"2022-04-13T15:30:52.734348Z","shell.execute_reply.started":"2022-04-13T15:30:50.213726Z","shell.execute_reply":"2022-04-13T15:30:52.733626Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n                 input_shape = (48, 48, 1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n                 input_shape = (48, 48, 1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# Block #2: second CONV => RELU => CONV => RELU => POOL\n# layer set\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# Block #3: third CONV => RELU => CONV => RELU => POOL\n# layer set\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# Block #4: third CONV => RELU => CONV => RELU => POOL\n# layer set\nmodel.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# Block #5: first set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(64, kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block #6: second set of FC => RELU layers\nmodel.add(Dense(64, kernel_initializer=\"he_normal\"))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block #7: softmax classifier\nmodel.add(Dense(7, kernel_initializer=\"he_normal\"))\nmodel.add(Activation(\"softmax\"))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:52.735464Z","iopub.execute_input":"2022-04-13T15:30:52.736197Z","iopub.status.idle":"2022-04-13T15:30:55.484223Z","shell.execute_reply.started":"2022-04-13T15:30:52.736159Z","shell.execute_reply":"2022-04-13T15:30:55.483541Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.0004),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:30:58.114883Z","iopub.execute_input":"2022-04-13T15:30:58.115440Z","iopub.status.idle":"2022-04-13T15:30:58.132322Z","shell.execute_reply.started":"2022-04-13T15:30:58.115401Z","shell.execute_reply":"2022-04-13T15:30:58.131600Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nearly=EarlyStopping(monitor='val_loss',patience=4)\nreduction=ReduceLROnPlateau(patience=2,monitor='val_loss',factor=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:31:01.499116Z","iopub.execute_input":"2022-04-13T15:31:01.499653Z","iopub.status.idle":"2022-04-13T15:31:01.504976Z","shell.execute_reply.started":"2022-04-13T15:31:01.499616Z","shell.execute_reply":"2022-04-13T15:31:01.504280Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:31:03.604929Z","iopub.execute_input":"2022-04-13T15:31:03.605594Z","iopub.status.idle":"2022-04-13T15:31:03.609674Z","shell.execute_reply.started":"2022-04-13T15:31:03.605557Z","shell.execute_reply":"2022-04-13T15:31:03.608538Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath='/kaggle/output/',\n                             monitor='val_loss',\n                             verbose=1, \n                             save_best_only=True,\n                             mode='min')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:31:06.101188Z","iopub.execute_input":"2022-04-13T15:31:06.101447Z","iopub.status.idle":"2022-04-13T15:31:06.105442Z","shell.execute_reply.started":"2022-04-13T15:31:06.101420Z","shell.execute_reply":"2022-04-13T15:31:06.104779Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_data,epochs=100,validation_data=test_data,callbacks=[early,reduction])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:31:24.386877Z","iopub.execute_input":"2022-04-13T15:31:24.387160Z","iopub.status.idle":"2022-04-13T16:15:05.097023Z","shell.execute_reply.started":"2022-04-13T15:31:24.387129Z","shell.execute_reply":"2022-04-13T16:15:05.096280Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\nnb_train_samples = 28273\nnb_validation_samples = 3534\n\n# We need to recreate our validation generator with shuffle = false\nvalidation_generator = img_gen.flow_from_directory(\n        '/kaggle/input/fer2013/test',\n        color_mode = 'grayscale',\n        target_size=(50, 50),\n        batch_size=64,\n        class_mode='categorical',\n        shuffle=False)\n\nclass_labels = validation_generator.class_indices\nclass_labels = {v: k for k, v in class_labels.items()}\nclasses = list(class_labels.values())\n\n#Confution Matrix and Classification Report\nY_pred = model.predict_generator(validation_generator)\ny_pred = np.argmax(Y_pred, axis=1)\n\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\ncnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n\nplt.imshow(cnf_matrix, interpolation='nearest')\nplt.colorbar()\ntick_marks = np.arange(len(classes))\n_ = plt.xticks(tick_marks, classes, rotation=90)\n_ = plt.yticks(tick_marks, classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:15:05.098889Z","iopub.execute_input":"2022-04-13T16:15:05.101403Z","iopub.status.idle":"2022-04-13T16:15:16.832954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_generator = img_gen.flow_from_directory(\n        '/kaggle/input/fer2013/test',\n        color_mode = 'grayscale',\n        target_size=(50, 50),\n        batch_size=64,\n        class_mode='categorical',\n        shuffle=False)\n\nclass_labels = validation_generator.class_indices\nclass_labels = {v: k for k, v in class_labels.items()}\nclasses = list(class_labels.values())\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:15:16.841629Z","iopub.execute_input":"2022-04-13T16:15:16.842013Z","iopub.status.idle":"2022-04-13T16:15:17.072966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport os\nimport cv2\nimport numpy as np\nfrom os import listdir\nfrom os.path import isfile, join\nimport re\nimport matplotlib.pyplot as plt\n\ndef draw_test(name, pred, im, true_label):\n    BLACK = [0,0,0]\n    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 300 ,cv2.BORDER_CONSTANT,value=BLACK)\n    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n    cv2.imshow(name,expanded_image)\n\n\ndef getRandomImage(path, img_width, img_height):\n    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n    random_directory = np.random.randint(0,len(folders))\n    path_class = folders[random_directory]\n    file_path = path + path_class\n    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n    random_file_index = np.random.randint(0,len(file_names))\n    image_name = file_names[random_file_index]\n    final_path = file_path + \"/\" + image_name\n    return image.load_img(final_path, target_size = (img_width, img_height),grayscale=True), final_path, path_class\n\n# dimensions of our images\nimg_width, img_height = 48, 48\n\n# We use a very small learning rate \n#model.compile(loss = 'categorical_crossentropy',\n \n    #optimizer = RMSprop(lr = 0.001),\n     #         metrics = ['accuracy'])\n\nfiles = []\npredictions = []\ntrue_labels = []\n\n#fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 12))\n#plt.subplots_adjust(hspace=0.5)\n#fig.suptitle(\"Model Predictions\", fontsize=18, y=0.95)\n# predicting images\nfor i in range(0, 10):\n    path = '/kaggle/input/fer2013/test/' \n    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n    files.append(final_path)\n    true_labels.append(true_label)\n    x = image.img_to_array(img)\n    x = x * 1./255\n    x = np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n    classes = model.predict(images, batch_size = 10)\n    predictions.append(classes)\n    \nfor i in range(0, len(files)):\n    \n    #print(np.argmax(predictions[i][0]))\n    #print(class_labels[np.argmax(predictions[i][0])])\n    pred=\"predited - \"+ class_labels[np.argmax(predictions[i][0])]\n    true=\"true - \"+ true_labels[i]\n    image = cv2.imread((files[i]))\n    image = cv2.resize(image, (400,400), fx=3, fy=3, interpolation = cv2.INTER_CUBIC)\n    cv2.putText(image, pred, (10, 40) , cv2.FONT_HERSHEY_SIMPLEX,1.2, (255,0,25), 3)\n    cv2.putText(image, true, (10, 90) , cv2.FONT_HERSHEY_SIMPLEX,1.2, (0,0,250), 3)\n    plt.imshow(image)\n    plt.show()\n    #draw_test(\"Prediction\", pred, image, true)\n    cv2.waitKey(0)\n\ncv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:25:24.465040Z","iopub.execute_input":"2022-04-13T16:25:24.465412Z","iopub.status.idle":"2022-04-13T16:25:26.998556Z","shell.execute_reply.started":"2022-04-13T16:25:24.465377Z","shell.execute_reply":"2022-04-13T16:25:26.997883Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data=pd.read_json('/kaggle/input/news-category-dataset/News_Category_Dataset_v2.json')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}